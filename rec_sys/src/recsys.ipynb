{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System - Project 2\n",
    "\n",
    "### [0. Imports](#0)\n",
    "\n",
    "### [1. Data Exploration](#1)\n",
    "\n",
    "### [2. Model Building](#2)\n",
    "\n",
    "### [3. Cross Validation](#3)\n",
    "\n",
    "### [4. Run Model](#4)\n",
    "\n",
    "### [5. Produce Predictions](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports <a class=\"anchor\" id=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from functions import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section we analyse the collected data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow on with the data split. As the matrices we will be working with are sparse, we will use the `sp.lil_matrix` representation:<br>\n",
    "    \n",
    "An array (self.rows) of rows, each of which is a sorted list of column indices of non-zero elements The corresponding nonzero values are stored in similar fashion in self.data.\n",
    "    \n",
    "\n",
    "The following function will be used to split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, p_test=0.1, seed=516):\n",
    "    \"\"\"\n",
    "    split the ratings to training data and test data.\n",
    "    ***INPUT***\n",
    "    :param min_num_ratings: all users and items we keep must have at least min_num_ratings\n",
    "                            per user and per item. \n",
    "    :param p_test: probability for test split\n",
    "    :param seed: seed to use in random split\n",
    "    ***OUTPUT***\n",
    "    :return train: data for training\n",
    "    :return test: data for test\n",
    "    \"\"\"\n",
    "    np.random.seed(seed) \n",
    "\n",
    "    # initialize matrix\n",
    "    train = sp.lil_matrix(ratings.shape)\n",
    "    test  = sp.lil_matrix(ratings.shape)\n",
    "    \n",
    "    nz_items, nz_users = ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for idx in zip(nz_items, nz_users):\n",
    "        if np.random.rand() > p_test:\n",
    "            train[idx] = ratings[idx]\n",
    "        else:\n",
    "            test[idx] = ratings[idx]\n",
    "            \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Building<a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Initialization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\n",
    "    ***INPUT***\n",
    "    :param train: data for train\n",
    "    :param num_features: nummber of features for matrix factorization\n",
    "    ***OUTPUT***\n",
    "    :return user_features: user's matrix\n",
    "    :return item_features: item's matrix\n",
    "    \"\"\"\n",
    "    # get shapes    \n",
    "    num_item, num_user = train.get_shape()\n",
    "\n",
    "    # random initialization\n",
    "    user_features = np.random.rand(num_features, num_user)\n",
    "    item_features = np.random.rand(num_features, num_item)\n",
    "\n",
    "    # start by item features.\n",
    "    item_nnz = train.getnnz(axis=1)\n",
    "    item_sum = train.sum(axis=1)\n",
    "\n",
    "    for ind in range(num_item):\n",
    "        item_features[0, ind] = item_sum[ind, 0] / item_nnz[ind]\n",
    "        \n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(train, num_features, seed):\n",
    "    \"\"\"\n",
    "    Initializes parameters tu use in ALS\n",
    "    ***INPUT***\n",
    "    :param train: data for train\n",
    "    :param num_features: number of features for Matrix factorization\n",
    "    ***OUTPUT***\n",
    "    :param seed: seed for random generator\n",
    "    :return user_features: user's matrix\n",
    "    :return item_features: item's matrix\n",
    "    :return bias_user: user's bias vector\n",
    "    :return bias_item: item's bias vector\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)  #np.random.seed(84)\n",
    "    \n",
    "    # initialize biases\n",
    "    num_items, num_users = train.shape\n",
    "    bias_item = np.zeros(num_items) #np.random.rand(num_items) - 0.5\n",
    "    bias_user = np.zeros(num_users) #np.random.rand(num_users) - 0.5\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    return user_features, item_features, bias_item, bias_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Update**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update `user features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def update_user_feature(train, item_features, lambda_user,\n",
    "                        nnz_items_per_user, nz_user_itemindices, \n",
    "                        bias_item, bias_user, lambda_bias_user):   \n",
    "    \"\"\"\n",
    "    Update user feature matrix, for fixed item matrix\n",
    "    ***INPUT***\n",
    "    :param train: data for train\n",
    "    :param item_features: item's matrix\n",
    "    :param lambda_user: regularization parameter \n",
    "    :param nnz_items_per_user: non zero items per each user\n",
    "    :param nz_user_itemindices: indices of non zero users per item\n",
    "    :param bias_item: bias per item\n",
    "    :param bias_user: bias per user\n",
    "    :param lambda_bias_user: regularization parameter for user bias\n",
    "    ***OUTPUT***\n",
    "    :return user_features_new: updated user's matrix\n",
    "    :return bias_user_new: updated bias user\n",
    "    \"\"\"\n",
    "    \n",
    "    num_users = train.shape[1]\n",
    "    bias_user_new = np.zeros(num_users)\n",
    "    k = item_features.shape[0]\n",
    "    lambda_I = lambda_user * sp.eye(k)\n",
    "    user_features_new = np.zeros((k, num_users))\n",
    "    \n",
    "    for user in range(num_users):\n",
    "        # extract the columns corresponding to the prediction for the given item\n",
    "        M = item_features[:, nz_user_itemindices[user]]\n",
    "        \n",
    "        # get non zero values\n",
    "        user_nz = train[nz_user_itemindices[user] , user].toarray().squeeze()\n",
    "        bias_item_nz = bias_item[nz_user_itemindices[user]]\n",
    "        \n",
    "        # update column of user features\n",
    "        user_features_new = update_column_user(user, user_nz, nnz_items_per_user, M,\n",
    "                                                        lambda_I, user_features_new)\n",
    "\n",
    "        # update user bias\n",
    "        bias_user_new = update_user_bias(user, user_nz, bias_item_nz, user_features_new,\n",
    "                                         nnz_items_per_user, M, bias_user_new, lambda_bias_user)\n",
    "    \n",
    "    return user_features_new, bias_user_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update `item features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def update_item_feature(train, user_features, lambda_item,\n",
    "                        nnz_users_per_item, nz_item_userindices, \n",
    "                        bias_item, bias_user, lambda_bias_item):\n",
    "    \"\"\"\n",
    "    Update item feature matrix.\n",
    "    ***INPUT***\n",
    "    :param train: data for train\n",
    "    :param user_features: item's matrix\n",
    "    :param lambda_item: regularization parameter \n",
    "    :param nnz_users_per_item: non zero users per each item\n",
    "    :param nz_item_userindices: indices of non zero items per user\n",
    "    :param bias_item: bias per item\n",
    "    :param bias_user: bias per user\n",
    "    :param lambda_bias_item: regularization parameter for item bias\n",
    "    ***OUTPUT***\n",
    "    :return user_features_new: updated user's matrix\n",
    "    :return bias_user_new: updated bias user\n",
    "    \"\"\"\n",
    "    \n",
    "    num_items = train.shape[0]\n",
    "    bias_item_new = np.zeros(num_items)\n",
    "    k = user_features.shape[0]  \n",
    "    lambda_I = lambda_item * sp.eye(k)\n",
    "    item_features_new = np.zeros((k, num_items))\n",
    "    \n",
    "    for item in range(num_items):\n",
    "        # extract the columns corresponding to the prediction for the given user\n",
    "        M = user_features[:, nz_item_userindices[item]]\n",
    "        \n",
    "        # get non zero values\n",
    "        item_nz = train[item, nz_item_userindices[item]].toarray().squeeze()\n",
    "        bias_user_nz = bias_user[nz_item_userindices[item]]\n",
    "\n",
    "        # update column of item features\n",
    "        item_features_new = update_column_item(item, item_nz, nnz_users_per_item, M,\n",
    "                                                        lambda_I, item_features_new)\n",
    "        # update item bias\n",
    "        bias_item_new = update_item_bias(item, item_nz, bias_user_nz, item_features_new,\n",
    "                                         nnz_users_per_item, M, bias_item_new, lambda_bias_item)\n",
    "\n",
    "    return item_features_new, bias_item_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Factorization with ALS**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following auxiliar functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function runs the `ALS`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_ALS(train, user_features, item_features, bias_user, bias_item, lambda_user,lambda_item,\n",
    "            lambda_bias_item, lambda_bias_user, nnz_items_per_user, nz_user_itemindices,\n",
    "            nnz_users_per_item, nz_item_userindices, nz_train, stop_criterion):\n",
    "    \"\"\"\n",
    "    Performs Alternating Least Squares\n",
    "    ***INPUT***\n",
    "    :param train: data used for training\n",
    "    :param user_features: user's matrix\n",
    "    :param item_features: item's matrix\n",
    "    :param bias_user: array with bias for users\n",
    "    :param bias_item: array with bias for items\n",
    "    :param lambda_user: regularization parameter for users\n",
    "    :param lambda_item: regularization parameter for items\n",
    "    :param lambda_bias_item: regularization parameter for items' biases\n",
    "    :param lambda_bias_user: regularization parameter for users' biases\n",
    "    :param nnz_items_per_user: # of non zero items per user\n",
    "    :param nz_user_itemindices: indices of non zero users per item\n",
    "    :param nnz_users_per_item: # of non zero users per item\n",
    "    :param nz_item_userindices: indices of non zero items per user\n",
    "    :param nz_train: tuple of non zero (row, col)\n",
    "    :param stop_criterion: minimum difference between two consecutive iterations\n",
    "    ***OUTPUT***\n",
    "    :return user_features: user's matrix\n",
    "    :return item_features: item's matrix\n",
    "    :return bias_user: user's bias vector\n",
    "    :return bias_item: item's bias vector\n",
    "    \"\"\"\n",
    "    # define parameters\n",
    "    change = 1\n",
    "    error_list = [0]\n",
    "    \n",
    "    print(\"\\nstart the ALS algorithm with biases...\")\n",
    "    while change > stop_criterion:\n",
    "        \n",
    "        # update user feature & item feature\n",
    "        user_features, bias_user = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices, \n",
    "            bias_item, bias_user, lambda_bias_user)\n",
    "        \n",
    "        item_features, bias_item = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices, \n",
    "            bias_item, bias_user, lambda_bias_item)\n",
    "\n",
    "        error = compute_error_ALS(train, user_features, item_features, \n",
    "                                  bias_user, bias_item, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "    \n",
    "    return user_features, item_features, bias_user, bias_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ALS_bias(train, test, num_features,lambda_user, lambda_item, lambda_bias_user,\n",
    "             lambda_bias_item, stop_criterion, seed):\n",
    "    \"\"\"\n",
    "    Alternating Least Squares (ALS) algorithm with biases.\n",
    "    ***INPUT***\n",
    "    :param train: data for train\n",
    "    :param test: data for test\n",
    "    :param num_features: number of features for Matrix factorization\n",
    "    :param lambda_user: regularization parameter for user\n",
    "    :param lambda_item: regularization parameter for item \n",
    "    :param lambda_bias_user: regularization parameter for user bias\n",
    "    :param lambda_bias_item: regularization parameter for item bias\n",
    "    :param stop_criterion: minimum difference between two consecutive iterations\n",
    "    :param seed: seed for random generator\n",
    "    ***OUTPUT***\n",
    "    :return user_features: user's matrix\n",
    "    :return item_features: item's matrix\n",
    "    :return bias_user: user's bias vector\n",
    "    :return bias_item: item's bias vector\n",
    "    :return rmse: rmse error\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize parameters:\n",
    "    user_features, item_features, bias_item, bias_user = initialize_parameters(train, num_features,seed)\n",
    "    \n",
    "    # get non zero values\n",
    "    nz_row ,nz_col, nz_train, nnz_users_per_item, nz_item_userindices, nnz_items_per_user, nz_user_itemindices = get_non_zero_values(train)\n",
    "    \n",
    "    # run ALS\n",
    "    user_features, item_features, bias_user, bias_item = run_ALS(\n",
    "        train,\n",
    "        user_features, item_features,\n",
    "        bias_user, bias_item,\n",
    "        lambda_user, lambda_item, \n",
    "        lambda_bias_item, lambda_bias_user,\n",
    "        nnz_items_per_user, nz_user_itemindices, \n",
    "        nnz_users_per_item, nz_item_userindices,\n",
    "        nz_train,\n",
    "        stop_criterion)\n",
    "\n",
    "    # evaluate the test error\n",
    "    rmse = evaluate(test, user_features, item_features, bias_user, bias_item)\n",
    "    \n",
    "    return user_features, item_features, bias_user, bias_item, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross Validation<a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CV_boxplot(errors, n_features):\n",
    "    \"\"\"\n",
    "    Plots a box plot for CV tested with different number of features\n",
    "    ***INPUT***\n",
    "    :param errors: errors for different number of features tested\n",
    "    :param n_features: labels for plot\n",
    "    \"\"\"\n",
    "    _ = plt.boxplot(errors, labels = n_features, meanline=True, autorange= True)\n",
    "    plt.title(\"Error for different number of features\")\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Test error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cross Validation` will be performed in order to minimize the overfitting error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CV(ratings, ALS_parameters, k_folds, seeds):\n",
    "    \"\"\"\n",
    "    Performs CV over the number of specified folds.\n",
    "    Plots if True\n",
    "    ***INPUT***\n",
    "    :param ratings: values to consider for data split\n",
    "    :param ALS-parameters: list that contain all the parameters for ALS\n",
    "    :param k_folds: number of folds to test\n",
    "    :param seeds: list of seeds to apply for consecutive folds\n",
    "    ***OUTPUT***\n",
    "    :return user_features_avg: matrix of users avereged over folds\n",
    "    :return item_features_avg: matrix of items avereged over folds\n",
    "    :return bias_user_avg: array of biases per user avereged over folds\n",
    "    :return bias_item_avg: array of biases per item avereged over folds\n",
    "    :return rmse_avg: CV mean error avereged over folds\n",
    "    \"\"\"\n",
    "    \n",
    "    # define list to append folds values\n",
    "    user_features_folds = []; item_features_folds = []; \n",
    "    bias_user_folds= []; bias_item_folds = []; \n",
    "    error_folds=[]\n",
    "    \n",
    "    for fold_id in range(k_folds):\n",
    "        train_k, test_k = split_data(ratings, 0.1, seeds[fold_id])\n",
    "\n",
    "        user_features, item_features, bias_user, bias_item, rmse = ALS_bias(train_k, test_k, ALS_parameters[0],\n",
    "                                                                           ALS_parameters[1], ALS_parameters[2], \n",
    "                                                                           ALS_parameters[3], ALS_parameters[4],\n",
    "                                                                           ALS_parameters[5], seed=seeds[fold_id])\n",
    "\n",
    "        print(\"Error for fold ,\",fold_id+1, 'is: ', rmse)\n",
    "\n",
    "        # append fold values\n",
    "        user_features_folds.append(user_features); \n",
    "        item_features_folds.append(item_features)\n",
    "        bias_user_folds.append(bias_user)\n",
    "        bias_item_folds.append(bias_item)\n",
    "        error_folds.append(rmse)\n",
    "\n",
    "        #average parameters\n",
    "        user_features_avg, item_features_avg, bias_user_avg, bias_item_avg, rmse_avg =  average_parameters(user_features_folds,\n",
    "                                                                             item_features_folds, bias_user_folds,\n",
    "                                                                                 bias_item_folds, error_folds)\n",
    "\n",
    "    return user_features_avg, item_features_avg, bias_user_avg, bias_item_avg, rmse_avg, error_folds\n",
    "    \n",
    "def average_parameters(user_features_folds, item_features_folds,bias_user_folds,\n",
    "                       bias_item_folds,error_folds):\n",
    "    \"\"\"\n",
    "    Performs average on matrices obtained for each fold\n",
    "    ***INPUT***\n",
    "    :param user_features_folds: array with user's matrix for each fold\n",
    "    :param item_features_folds: array with item's matrix for each fold\n",
    "    :param bias_user_folds: array with user biases array for each fold\n",
    "    :param bias_item_folds: array with item biases array for each fold\n",
    "    :param error_folds: array with error for each fold\n",
    "    ***OUTPUT***\n",
    "    :return user_features: matrix of users avereged over folds\n",
    "    :return item_features: matrix of items avereged over folds\n",
    "    :return bias_user: array of biases per user avereged over folds\n",
    "    :return bias_item: array of biases per item avereged over folds\n",
    "    :return rmse: CV mean error avereged over folds\n",
    "    \"\"\"\n",
    "    # average arrays and return final matrices:\n",
    "    user_features = np.mean(user_features_folds, axis = 0)\n",
    "    item_features = np.mean(item_features_folds, axis = 0)\n",
    "    bias_user = np.mean(bias_user_folds, axis = 0)\n",
    "    bias_item = np.mean(bias_item_folds, axis = 0)\n",
    "    rmse = np.mean(error_folds, axis = 0)\n",
    "    \n",
    "    return user_features, item_features, bias_user, bias_item, rmse\n",
    "  \n",
    "\n",
    "def ALS_cross_validation(ratings, k_folds, ALS_parameters, plot_n_features = False, n_features = []):\n",
    "    \"\"\"\n",
    "    Performs Cross Validation.\n",
    "    ***INPUT***\n",
    "    :param ratings: values to consider for data split\n",
    "    :param k_folds: number of folds to test\n",
    "    :param plot_n_features: boolean to decide if CV will be ran for different number of features\n",
    "    :param n_features: vector with features to test (if plot_n_features == True)\n",
    "    :param ALS_parameters: list that contains the parameters to apply in ALS: [0]- # of features\n",
    "                            [1]- lambda_user\n",
    "                            [2]- lambda_item\n",
    "                            [3]- lambda_bias\n",
    "                            [4]- lambda_bias_item\n",
    "                            [5]- stop_criterion\n",
    "    ***OUTPUT***\n",
    "    :return user_features: matrix of users avereged over folds (corresponding to min rmse)\n",
    "    :return item_features: matrix of items avereged over folds (corresponding to min rmse)\n",
    "    :return bias_user: array of biases per user avereged over folds (corresponding to min rmse)\n",
    "    :return bias_item: array of biases per item avereged over folds (corresponding to min rmse)\n",
    "    :return rmse: CV mean error avereged over folds (corresponding to min rmse)\n",
    "    \"\"\"\n",
    "    \n",
    "    # seeds to use in data spliting\n",
    "    seeds = np.random.randint(1, 500, size = k_folds)\n",
    "    print(seeds)\n",
    "    \n",
    "    # perform ALS for different number of features\n",
    "    if (plot_n_features == True):\n",
    "        errors = []\n",
    "        rmse_min = 10  #initialize with high value\n",
    "        for idx in range(len(n_features)):\n",
    "            ALS_parameters[0] = n_features[idx]\n",
    "            user_features_idx, item_features_idx, bias_user_idx, \\\n",
    "            bias_item_idx, rmse_idx, error_folds = CV(ratings, ALS_parameters, k_folds, seeds)\n",
    "            if rmse_idx < rmse_min: \n",
    "                user_features = user_features_idx\n",
    "                item_features =item_features_idx\n",
    "                bias_user= bias_user_idx\n",
    "                bias_item = bias_item_idx\n",
    "                rmse = rmse_idx\n",
    "                rmse_min = rmse_idx\n",
    "            errors.append(error_folds)  \n",
    "\n",
    "        #plot results\n",
    "        CV_boxplot(errors, n_features)\n",
    "    \n",
    "    # performs ALS for fixed number of features\n",
    "    else: \n",
    "        user_features, item_features, bias_user, \\\n",
    "        bias_item, rmse, error_folds =  CV(ratings, ALS_parameters, k_folds, seeds)\n",
    "        \n",
    "    return  user_features, item_features, bias_user, bias_item, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Model (RUN)<a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data loading: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"./Data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters to use:\n",
    "\"\"\"\n",
    "[0]- number of features\n",
    "[1]- lambda_user\n",
    "[2]- lambda_item\n",
    "[3]- lambda_bias\n",
    "[4]- lambda_bias_item\n",
    "[5]- stop_criterion\n",
    "\"\"\"\n",
    "\n",
    "def run(option , parameters, folds=4):\n",
    "    \"\"\"\n",
    "    Function to run the model. Can run either one of the three options:\n",
    "        1: ALS\n",
    "        2: ALS with cross validation\n",
    "        3: ALS with cross-validation and plot for different features\n",
    "    ***INPUT***\n",
    "    :param option: \n",
    "    :param parameters: \n",
    "    :param folds: \n",
    "    ***OUTPUT***\n",
    "    \"\"\"\n",
    "    # RUN ALS\n",
    "    if option == 1:\n",
    "        # same as running cross validation with 1 fold\n",
    "        user_features, item_features, bias_user, bias_item, rmse = ALS_cross_validation(ratings, 1, parameters) \n",
    "    \n",
    "    # RUN ALS WITH CV\n",
    "    elif option == 2:\n",
    "        user_features, item_features, bias_user, bias_item, rmse = ALS_cross_validation(ratings, folds, parameters)\n",
    "        \n",
    "    # RUN ALS WITH CV AND PLOT FOR DIFFERENT NUMBER OF FEATURES\n",
    "    else:\n",
    "        n_features = [20, 25, 30, 35, 40]\n",
    "        user_features, item_features, bias_user, bias_item, rmse = ALS_cross_validation(ratings, folds, parameters,\n",
    "                                                                                        plot_n_features=True,\n",
    "                                                                                        n_features=n_features)\n",
    "        \n",
    "    return user_features, item_features, bias_user, bias_item, rmse\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose which version to run:**\n",
    "- 1: `ALS`\n",
    "- 2: `ALS with Cross Validation`\n",
    "- 3: `ALS with Cross Validation and plot for different features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396]\n",
      "\n",
      "start the ALS algorithm with biases...\n",
      "RMSE on training set: 0.9916097125655676.\n",
      "RMSE on training set: 0.9799149946047435.\n",
      "RMSE on training set: 0.9648702780440435.\n",
      "RMSE on training set: 0.9485932024896112.\n",
      "RMSE on training set: 0.9368582478882101.\n",
      "RMSE on training set: 0.9288207905514376.\n",
      "RMSE on training set: 0.9235377200888822.\n",
      "RMSE on training set: 0.9200028253769351.\n",
      "RMSE on training set: 0.9175849139800518.\n",
      "RMSE on training set: 0.9158861020482506.\n",
      "RMSE on training set: 0.9146559751124483.\n",
      "RMSE on training set: 0.9137372585789946.\n",
      "RMSE on training set: 0.91303075036754.\n",
      "RMSE on training set: 0.9124731260070268.\n",
      "RMSE on training set: 0.91202315488226.\n",
      "RMSE on training set: 0.91165329994521.\n",
      "RMSE on training set: 0.9113446439811186.\n",
      "RMSE on training set: 0.9110838145241826.\n",
      "RMSE on training set: 0.9108610958495913.\n",
      "RMSE on training set: 0.9106692479544896.\n",
      "RMSE on training set: 0.9105027516500401.\n",
      "RMSE on training set: 0.9103573148415639.\n",
      "RMSE on training set: 0.9102295419882735.\n",
      "RMSE on training set: 0.9101167075532802.\n",
      "RMSE on training set: 0.910016597060707.\n",
      "RMSE on training set: 0.9099273929892839.\n",
      "RMSE on training set: 0.9098475909971158.\n",
      "RMSE on training set: 0.9097759370805144.\n",
      "RMSE on training set: 0.9097113794833188.\n",
      "RMSE on training set: 0.9096530312283169.\n",
      "RMSE on training set: 0.9096001404746776.\n",
      "RMSE on training set: 0.9095520667772833.\n",
      "RMSE on training set: 0.9095082618979397.\n",
      "RMSE on training set: 0.9094682541981318.\n",
      "RMSE on training set: 0.9094316358957781.\n",
      "RMSE on training set: 0.9093980526389814.\n",
      "RMSE on training set: 0.909367194967536.\n",
      "RMSE on training set: 0.9093387913172296.\n",
      "RMSE on training set: 0.9093126022849399.\n",
      "RMSE on training set: 0.9092884159218279.\n",
      "RMSE on training set: 0.9092660438620204.\n",
      "RMSE on training set: 0.9092453181276812.\n",
      "RMSE on training set: 0.9092260884797856.\n",
      "RMSE on training set: 0.9092082202080245.\n",
      "RMSE on training set: 0.9091915922737017.\n",
      "RMSE on training set: 0.9091760957365594.\n",
      "RMSE on training set: 0.909161632410609.\n",
      "RMSE on training set: 0.9091481137055737.\n",
      "RMSE on training set: 0.9091354596198298.\n",
      "RMSE on training set: 0.9091235978581006.\n",
      "RMSE on training set: 0.9091124630529571.\n",
      "RMSE on training set: 0.9091019960736713.\n",
      "RMSE on training set: 0.9090921434094359.\n",
      "RMSE on training set: 0.9090828566166337.\n",
      "RMSE on training set: 0.9090740918218538.\n",
      "RMSE on training set: 0.9090658092739095.\n",
      "RMSE on training set: 0.9090579729393017.\n",
      "RMSE on training set: 0.9090505501364551.\n",
      "RMSE on training set: 0.9090435112047842.\n",
      "RMSE on training set: 0.9090368292051865.\n",
      "RMSE on training set: 0.9090304796489846.\n",
      "RMSE on training set: 0.9090244402527146.\n",
      "RMSE on training set: 0.9090186907164156.\n",
      "RMSE on training set: 0.9090132125233374.\n",
      "RMSE on training set: 0.9090079887591714.\n",
      "RMSE on training set: 0.9090030039490835.\n",
      "test RMSE after running ALS: 0.9791840437298989.\n",
      "Error for fold , 1 is:  0.97918404373\n"
     ]
    }
   ],
   "source": [
    "parameters = [25, 0.1, 0.1, 0.1, 0.1, 0.5e-5]\n",
    "user_features, item_features, bias_user, bias_item, rmse = run(option=1 , parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Produce Predictions<a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce `submission`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SUBMISSION_SAMPLES_PATH = \"./Data/sample_submission.csv\"\n",
    "samples_submission      = samples_csv_submission(SUBMISSION_SAMPLES_PATH)\n",
    "\n",
    "create_csv_submission(samples_submission, item_features, user_features, bias_item, bias_user, 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
